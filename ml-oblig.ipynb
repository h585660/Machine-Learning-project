{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1436c76",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-25T15:15:55.088050Z",
     "iopub.status.busy": "2023-10-25T15:15:55.087459Z",
     "iopub.status.idle": "2023-10-25T15:15:56.162293Z",
     "shell.execute_reply": "2023-10-25T15:15:56.160150Z"
    },
    "papermill": {
     "duration": 1.082885,
     "end_time": "2023-10-25T15:15:56.164763",
     "exception": true,
     "start_time": "2023-10-25T15:15:55.081878",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'random_forest_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrandom_forest_model.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m scaler \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Definer kollonner\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'random_forest_model.pkl'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "model = joblib.load('random_forest_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Definer kollonner\n",
    "categorical_columns = ['gender', 'dialysisrenalendstage', 'asthma', 'irondef', 'pneum', \n",
    "                       'substancedependence', 'psychologicaldisordermajor', 'depress', 'psychother',\n",
    "                       'fibrosisandother', 'malnutrition']\n",
    "\n",
    "numerical_columns = ['rcount', 'hemo', 'hematocrit', 'neutrophils', 'sodium',\n",
    "                     'glucose', 'bloodureanitro', 'creatinine', 'bmi', 'pulse', 'respiration']\n",
    "\n",
    "test_data = pd.read_csv('test_data.csv', dtype={'gender': str})\n",
    "\n",
    "# test-data brukte double som 'gender' verdi, så endret dette for å passe modell\n",
    "test_data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "if '0.0' in test_data['gender'].unique():\n",
    "    test_data['gender'] = test_data['gender'].replace({'0.0': 'F'})\n",
    "if '1.0' in test_data['gender'].unique():\n",
    "    test_data['gender'] = test_data['gender'].replace({'1.0': 'M'})\n",
    "\n",
    "# modell ble generert uten facid, så dette måtte fjernes for å kunne kjøre test-data\n",
    "if 'facid' in test_data.columns:\n",
    "    test_data.drop('facid', axis=1, inplace=True)\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "test_data = pd.get_dummies(test_data, columns=categorical_columns)\n",
    "\n",
    "# skalering\n",
    "test_data[numerical_columns] = scaler.transform(test_data[numerical_columns])\n",
    "\n",
    "# Save the original 'id' column\n",
    "original_id = test_data['id'].copy()\n",
    "\n",
    "# Load the model's feature names\n",
    "try:\n",
    "    trained_feature_names = model.feature_names_in_\n",
    "except AttributeError:\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "# Endre rekkefølge\n",
    "test_data = test_data[['id'] + list(trained_feature_names)]\n",
    "\n",
    "# Bare bruk features fra modell\n",
    "length_of_stay_predictions = model.predict(test_data[trained_feature_names])\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    'id': original_id,\n",
    "    'lengthofstay': length_of_stay_predictions\n",
    "})\n",
    "\n",
    "# lagre forventet resultat\n",
    "result_df.to_csv('length_of_stay_predictions3.csv', index=False)\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c672d1bd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import joblib\n",
    "from scipy.stats import randint\n",
    "\n",
    "\n",
    "print(\"Laster data\")\n",
    "\n",
    "train_data = pd.read_csv('training_data.csv', parse_dates=['vdate'])\n",
    "metadata = pd.read_csv('metadata.csv')\n",
    "\n",
    "\n",
    "\n",
    "print(\"Forhåndsprosesserer\")\n",
    "\n",
    "train_data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# kollonner\n",
    "categorical_columns = ['gender', 'dialysisrenalendstage', 'asthma', 'irondef', 'pneum', \n",
    "                       'substancedependence', 'psychologicaldisordermajor', 'depress', 'psychother',\n",
    "                       'fibrosisandother', 'malnutrition']\n",
    "numerical_columns = ['rcount', 'hemo', 'hematocrit', 'neutrophils', 'sodium',\n",
    "                     'glucose', 'bloodureanitro', 'creatinine', 'bmi', 'pulse', 'respiration']\n",
    "\n",
    "\n",
    "train_data = pd.get_dummies(train_data, columns=categorical_columns)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_data[numerical_columns] = scaler.fit_transform(train_data[numerical_columns])\n",
    "\n",
    "\n",
    "selected_features = train_data.columns.difference(['id', 'vdate', 'discharged', 'facid', 'lengthofstay'])\n",
    "X = train_data[selected_features]\n",
    "y = train_data['lengthofstay']\n",
    "\n",
    "print(\"splitter datasett\")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Trener modell\")\n",
    "# Initialize and Train Model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate Model\n",
    "y_pred = model.predict(X_val)\n",
    "print(\"R2 Score:\", r2_score(y_val, y_pred))\n",
    "\n",
    "# Define Parameter Distributions\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'max_depth': [None] + list(randint(10, 30).rvs(size=3)),\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "print(\"Randomized search starter\")\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions, n_iter=50, cv=3, scoring='r2', n_jobs=-1, verbose=2)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Modellagring\")\n",
    "# Best Model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Save the best model \n",
    "joblib.dump(best_model, 'random_forest_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc32c035",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gradio as gr\n",
    "import joblib\n",
    "\n",
    "# Laster inn modellen og scaleren\n",
    "print(\"Loading model and scaler...\")\n",
    "model = joblib.load('random_forest_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Definerer kolonnene\n",
    "cat_cols = ['gender', 'dialysisrenalendstage', 'asthma', 'irondef', 'pneum', \n",
    "            'substancedependence', 'psychologicaldisordermajor', 'depress', 'psychother',\n",
    "            'fibrosisandother', 'malnutrition']\n",
    "\n",
    "num_cols = ['rcount', 'hemo', 'hematocrit', 'neutrophils', 'sodium',\n",
    "            'glucose', 'bloodureanitro', 'creatinine', 'bmi', 'pulse', 'respiration']\n",
    "\n",
    "# Prediksjon\n",
    "def predict_stay(*inputs):\n",
    "    input_data = pd.DataFrame([inputs], columns=num_cols + cat_cols)\n",
    "    input_data.fillna(method='ffill', inplace=True)\n",
    "    input_data = pd.get_dummies(input_data, columns=cat_cols)\n",
    "    input_data[num_cols] = scaler.transform(input_data[num_cols])\n",
    "    stay_length = model.predict(input_data)\n",
    "    return stay_length[0]\n",
    "\n",
    "# Definerer input-komponentene\n",
    "num_input_components = [gr.Number(label=col) for col in num_cols]\n",
    "gender_input_component = [gr.Radio(['F', 'M'], label='gender')]\n",
    "cat_input_components = [gr.Checkbox(label=col) for col in cat_cols if col != 'gender']\n",
    "\n",
    "# Kombinerer input-komponentene\n",
    "all_input_components = num_input_components + gender_input_component + cat_input_components\n",
    "\n",
    "# Lager Gradio-grensesnittet\n",
    "iface = gr.Interface(\n",
    "    fn=predict_stay,\n",
    "    inputs=all_input_components,\n",
    "    outputs=gr.Number(label=\"Estimated Length of Stay\")\n",
    ")\n",
    "\n",
    "# Starter Gradio-grensesnittet\n",
    "iface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5.918917,
   "end_time": "2023-10-25T15:15:56.994980",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-25T15:15:51.076063",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
